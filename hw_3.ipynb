{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Терминалогия, используемая в задании:\n",
    "* обучающая выборка - выборка, которая передается в метод fit / train;\n",
    "* валидационная выборка - выборка, которая получается при Hold-Out на 2 выборки (train, valid);\n",
    "* тестовая выборка - выборка, которая получается при Hold-Out на 3 выборки (train, valid, test);\n",
    "* ЛБ - лидерборд, выборка assignment_2_test.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from scipy.stats import probplot, ks_2samp\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bootstrap_samples(data: np.array, n_samples: int = 1000) -> np.array:\n",
    "    \"\"\"\n",
    "    Создание бутстреп-выборок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.array\n",
    "        Исходная выборка, которая будет использоваться для\n",
    "        создания бутстреп выборок.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_idx: np.array\n",
    "        Матрица индексов, для создания бутстреп выборок.\n",
    "\n",
    "    \"\"\"\n",
    "    bootstrap_idx = np.random.randint(\n",
    "        low=0, high=len(data), size=(n_samples, len(data))\n",
    "    )\n",
    "    return bootstrap_idx\n",
    "\n",
    "\n",
    "def create_bootstrap_metrics(y_true: np.array,\n",
    "                             y_pred: np.array,\n",
    "                             metric: callable,\n",
    "                             n_samlpes: int = 1000) -> List[float]:\n",
    "    \"\"\"\n",
    "    Вычисление бутстреп оценок.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true: np.array\n",
    "        Вектор целевой переменной.\n",
    "\n",
    "    y_pred: np.array\n",
    "        Вектор прогнозов.\n",
    "\n",
    "    metric: callable\n",
    "        Функция для вычисления метрики.\n",
    "        Функция должна принимать 2 аргумента: y_true, y_pred.\n",
    "\n",
    "    n_samples: int, optional, default = 1000\n",
    "        Количество создаваемых бутстреп выборок.\n",
    "        Опциональный параметр, по умолчанию, равен 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bootstrap_metrics: List[float]\n",
    "        Список со значениями метрики качества на каждой бустреп выборке.\n",
    "\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    if isinstance(y_true, pd.Series):\n",
    "        y_true = y_true.values\n",
    "\n",
    "    bootstrap_idx = create_bootstrap_samples(y_true)\n",
    "    for idx in bootstrap_idx:\n",
    "        y_true_bootstrap = y_true[idx]\n",
    "        y_pred_bootstrap = y_pred[idx]\n",
    "\n",
    "        score = metric(y_true_bootstrap, y_pred_bootstrap)\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def calculate_confidence_interval(scores: list, conf_interval: float = 0.95) -> Tuple[float]:\n",
    "    \"\"\"\n",
    "    Вычисление доверительного интервала.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scores: List[float / int]\n",
    "        Список с оценками изучаемой величины.\n",
    "\n",
    "    conf_interval: float, optional, default = 0.95\n",
    "        Уровень доверия для построения интервала.\n",
    "        Опциональный параметр, по умолчанию, равен 0.95.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    conf_interval: Tuple[float]\n",
    "        Кортеж с границами доверительного интервала.\n",
    "\n",
    "    \"\"\"\n",
    "    left_bound = np.percentile(\n",
    "        scores, ((1 - conf_interval) / 2) * 100\n",
    "    )\n",
    "    right_bound = np.percentile(\n",
    "        scores, (conf_interval + ((1 - conf_interval) / 2)) * 100\n",
    "    )\n",
    "\n",
    "    return left_bound, right_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_csv('train.csv')\n",
    "l_board = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index('TransactionID',inplace=True)\n",
    "l_board.set_index('TransactionID',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2987000</th>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987001</th>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987002</th>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987003</th>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987004</th>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>credit</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 393 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               isFraud  TransactionDT  TransactionAmt ProductCD  card1  card2  \\\n",
       "TransactionID                                                                   \n",
       "2987000              0          86400            68.5         W  13926    NaN   \n",
       "2987001              0          86401            29.0         W   2755  404.0   \n",
       "2987002              0          86469            59.0         W   4663  490.0   \n",
       "2987003              0          86499            50.0         W  18132  567.0   \n",
       "2987004              0          86506            50.0         H   4497  514.0   \n",
       "\n",
       "               card3       card4  card5   card6  ...  V330  V331  V332  V333  \\\n",
       "TransactionID                                    ...                           \n",
       "2987000        150.0    discover  142.0  credit  ...   NaN   NaN   NaN   NaN   \n",
       "2987001        150.0  mastercard  102.0  credit  ...   NaN   NaN   NaN   NaN   \n",
       "2987002        150.0        visa  166.0   debit  ...   NaN   NaN   NaN   NaN   \n",
       "2987003        150.0  mastercard  117.0   debit  ...   NaN   NaN   NaN   NaN   \n",
       "2987004        150.0  mastercard  102.0  credit  ...   0.0   0.0   0.0   0.0   \n",
       "\n",
       "              V334 V335  V336  V337  V338  V339  \n",
       "TransactionID                                    \n",
       "2987000        NaN  NaN   NaN   NaN   NaN   NaN  \n",
       "2987001        NaN  NaN   NaN   NaN   NaN   NaN  \n",
       "2987002        NaN  NaN   NaN   NaN   NaN   NaN  \n",
       "2987003        NaN  NaN   NaN   NaN   NaN   NaN  \n",
       "2987004        0.0  0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 393 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 180000 entries, 2987000 to 3166999\n",
      "Columns: 393 entries, isFraud to V339\n",
      "dtypes: float64(376), int64(3), object(14)\n",
      "memory usage: 541.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100001 entries, 3287000 to 3387000\n",
      "Columns: 393 entries, isFraud to V339\n",
      "dtypes: float64(376), int64(3), object(14)\n",
      "memory usage: 300.6+ MB\n"
     ]
    }
   ],
   "source": [
    "l_board.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1: сделать Hold-Out валидацию с разбиением, размер которого будет адеквтаным, по вашему мнению; разбиение проводить по id-транзакции (TransactionID), обучать модель градиетного бустинга любой реализации с подбором числа деревьев по early_stopping критерию до достижения сходимости. Оценить качество модели на валидационной выборке, оценить расхождение по сравнению с качеством на обучающей выборке и валидационной выборке. Оценить качество на ЛБ, сравнить с качеством на обучении и валидации. Сделать выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_features = train.select_dtypes(include=[np.object]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[object_features]= train[object_features].astype('category')\n",
    "l_board[object_features]= l_board[object_features].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_valid,y_train,y_valid = train_test_split(train.drop('isFraud',axis=1),train['isFraud'], test_size = 0.3 ,random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(data=x_train, label=y_train,categorical_feature=object_features.to_list())\n",
    "dvalid = lgb.Dataset(data=x_valid, label=y_valid,categorical_feature=object_features.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_estimators\": 20000,\n",
    "    \"n_jobs\": 15,\n",
    "    \"seed\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = lgb.train(\n",
    "    params=params,\n",
    "    train_set=dtrain,\n",
    "    num_boost_round=10000,\n",
    "    valid_sets=[dtrain, dvalid],\n",
    "    categorical_feature=object_features.to_list(),\n",
    "    early_stopping_rounds=90,\n",
    "    verbose_eval=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9999718098871575)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9564815499099788)])}),\n",
       " 1)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.best_score, model.best_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели на валидационной выборке 0,957  что кажеться очень хорошим результатом. При  этон на трайн почти единица. \n",
    "Что говорит, что модель сильно подстроилась по данные, но при этом разность не сильно большая меньеше 5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество на лидер борде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8496501937123049"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(l_board['isFraud'], model_1.predict(l_board.drop('isFraud',axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдаем сильное отличие показателя качества на валидации и лидерборде, почти 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2: сделать Hold-Out валидацию с разбиением на 3 выборки, разбиение проводить по id-транзакции (TransactionID), размер каждой выборки подобрать самостоятельно. Повторить процедуру из п.1. для каждой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid,x_test,y_valid,y_test = train_test_split(x_valid,y_valid, test_size = 0.4 ,random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32400 entries, 3083768 to 3127011\n",
      "Columns: 392 entries, TransactionDT to V339\n",
      "dtypes: category(14), float64(376), int64(2)\n",
      "memory usage: 94.1 MB\n"
     ]
    }
   ],
   "source": [
    "x_valid.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21600 entries, 3122360 to 3071062\n",
      "Columns: 392 entries, TransactionDT to V339\n",
      "dtypes: category(14), float64(376), int64(2)\n",
      "memory usage: 62.8 MB\n"
     ]
    }
   ],
   "source": [
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9542313280399443"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Скор на валидационной выборке\n",
    "roc_auc_score(y_valid, model_1.predict(x_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597253383379328"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Скор на тестовой выборке\n",
    "roc_auc_score(y_test, model_1.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно показатель качества не сильно отличается на валидационной и на тестовой выборке и их сильно преврсходит лидерборд. То есть модель на своих данных стабильна. Но как только появляются данне м ЛБ, все идет не так. Таким образом,  модель на ЛБ будет работать по доугому, видимо данные сильно отличаются"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3: построить доверительный интервал на данных из п.2 на основе бутстреп выборок, оценить качество модели на ЛБ относительно полученного доверительного интервала. Сделать выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Вот здесь я запутался. Для данного задания нужно обучать модель на полных данных или только на разделенных(x_train , за вычетом x_valid)).\n",
    "\n",
    "Сначало все сделал на x_train, потом посмотрел лекцию, там модель обучена на полном объеме данных. Переделал. И бустрап валидацию, так тже как и в задании делдал на тестовой выборке (самой маленькой)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(data=train.drop('isFraud',axis=1), label=train['isFraud'],categorical_feature=object_features.to_list())\n",
    "dvalid = lgb.Dataset(data=x_valid, label=y_valid,categorical_feature=object_features.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = lgb.train(\n",
    "    params=params,\n",
    "    train_set=dtrain,\n",
    "    num_boost_round=10000,\n",
    "    valid_sets=[dtrain,dvalid],\n",
    "    categorical_feature=object_features.to_list(),\n",
    "    early_stopping_rounds=90,\n",
    "    verbose_eval=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9999987941488887)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9999997936997556)])}),\n",
       " 1)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.best_score, model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999835498445154, 1.0)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# доверительный интервал на данных из п.2 на основе бутстреп выборок\n",
    "np.random.seed(15)\n",
    "scores = create_bootstrap_metrics(y_test, model_2.predict(x_test), roc_auc_score)\n",
    "\n",
    "calculate_confidence_interval(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8323428374893191"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Скор на лидерборде\n",
    "roc_auc_score(l_board['isFraud'], model_2.predict(l_board.drop('isFraud',axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вторым способом (не знаю как правильно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(data=x_train, label=y_train,categorical_feature=object_features.to_list())\n",
    "dvalid = lgb.Dataset(data=x_valid, label=y_valid,categorical_feature=object_features.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9999869003184734)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.954349331779755)])}),\n",
       " 1)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = lgb.train(\n",
    "    params=params,\n",
    "    train_set=dtrain,\n",
    "    num_boost_round=10000,\n",
    "    valid_sets=[dtrain,dvalid],\n",
    "    categorical_feature=object_features.to_list(),\n",
    "    early_stopping_rounds=90,\n",
    "    verbose_eval=None\n",
    ")\n",
    "model_3.best_score, model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8491836579831299"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Скор на лидерборде\n",
    "roc_auc_score(l_board['isFraud'], model_3.predict(l_board.drop('isFraud',axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Видимо данные сильно отличаются в моделе и лидерборде."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4: выполнить Adversarial Validation, подобрать объекты из обучающей выборки, которые сильно похожи на объекты из assignment_2_test.csv, и использовать их в качестве валидационного набора. Оценить качество модели на ЛБ, сделать выводы о полученных результатах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь я то же не очень понимаю задаание.\n",
    "Adversarial Validation между x_train и  x_valid?, так сделано в лекции , и в задании указано \n",
    "\n",
    " Цитата тз задания: \"Будем моделировать ситуацию отправки решения на лидерборд и сравнить значение метрики на лидерборде и на локальной валидации. Для других целей использовать выборку запрещено!.\"\n",
    "    \n",
    "    Но я не понимаю для чего так делать, это ничего не даст.\n",
    "    Нужно делать с данными которые для лидерборда, что бы понять как они отличаются.\n",
    "    Поскольу рабочих данных все прекрасно и так\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv = pd.concat([\n",
    "    train.drop('isFraud',axis=1), l_board.drop('isFraud',axis=1)], axis=0\n",
    ")\n",
    "y_adv = np.hstack((np.zeros(train.shape[0]), np.ones(l_board.shape[0])))\n",
    "assert x_adv.shape[0] == y_adv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv[object_features]= x_adv[object_features].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 280001 entries, 2987000 to 3387000\n",
      "Columns: 392 entries, TransactionDT to V339\n",
      "dtypes: category(14), float64(376), int64(2)\n",
      "memory usage: 813.4 MB\n"
     ]
    }
   ],
   "source": [
    "x_adv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), 280001)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_adv),len(y_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(data=x_adv, label=y_adv,categorical_feature=object_features.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9994740817546621)]),\n",
       "              'valid_1': OrderedDict([('auc', 1.0)])}),\n",
       " 1)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_adv = lgb.train(\n",
    "    params=params,\n",
    "    train_set=dtrain,\n",
    "    num_boost_round=10000,\n",
    "    valid_sets=[dtrain],\n",
    "    categorical_feature=object_features.to_list(),\n",
    "    early_stopping_rounds=90,\n",
    "    verbose_eval=None\n",
    ")\n",
    "model.best_score, model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_adv, model_adv.predictdictdictdict(x_adv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно 'auc' = 1 , распределение абсолютно разное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_adv.predict(train.drop('isFraud',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.1]    179827\n",
       "(0.1, 0.2]       100\n",
       "(0.2, 0.3]        43\n",
       "(0.3, 0.4]        19\n",
       "(0.4, 0.5]        10\n",
       "(0.5, 0.6]         1\n",
       "(0.6, 0.7]         0\n",
       "(0.7, 0.8]         0\n",
       "(0.8, 0.9]         0\n",
       "(0.9, 1.0]         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(\n",
    "    pred, bins=np.arange(0, 1.01, 0.1)\n",
    ").value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.5]    179999\n",
       "(0.5, 1.0]         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(\n",
    "    pred, bins=np.arange(0, 1.01, 0.5)\n",
    ").value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возмем на валидацию, все что больше или равно 0,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# индексы, где значение вероятности не иенее 0,5\n",
    "ind_val = np.where(pred>=0.1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ind_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = train.iloc[ind_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 173 entries, 3166742 to 3166998\n",
      "Columns: 393 entries, isFraud to V339\n",
      "dtypes: category(14), float64(376), int64(3)\n",
      "memory usage: 523.3 KB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= train.drop(X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179827 entries, 2987000 to 3166999\n",
      "Columns: 393 entries, isFraud to V339\n",
      "dtypes: category(14), float64(376), int64(3)\n",
      "memory usage: 523.8 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=X_train['isFraud']\n",
    "y_test=X_test['isFraud']\n",
    "X_train=X_train.drop('isFraud',axis=1)\n",
    "X_test=X_test.drop('isFraud',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(data=X_train, label=y_train,categorical_feature=object_features.to_list())\n",
    "dvalid = lgb.Dataset(data=X_test, label=y_test,categorical_feature=object_features.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(collections.OrderedDict,\n",
       "             {'training': OrderedDict([('auc', 0.9611678778725501)]),\n",
       "              'valid_1': OrderedDict([('auc', 0.9985207100591716)])}),\n",
       " 1)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = lgb.train(\n",
    "    params=params,\n",
    "    train_set=dtrain,\n",
    "    num_boost_round=10000,\n",
    "    valid_sets=[dtrain,dvalid],\n",
    "    categorical_feature=object_features.to_list(),\n",
    "    early_stopping_rounds=90,\n",
    "    verbose_eval=None\n",
    ")\n",
    "model_4.best_score, model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8720878429382346"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Скор на лидерборде\n",
    "roc_auc_score(l_board['isFraud'], model_4.predict(l_board.drop('isFraud',axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем ничего не получается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
